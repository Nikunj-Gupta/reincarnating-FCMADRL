dqn:
  layers: [64, 64]
  activations: ['relu', 'relu']
  learning_rate: 0.002
  clipnorm: 1.0
  gamma: 0.99
  epsilon: 1.0
  epsilon_decay: 0.9999
  epsilon_min: 0.1
  max_memory_len: 5000
  batch_size: 64
ddpg:
  std_dev: 0.2
  input_dims: 128
  input_activation: "relu"
  output_dims: 5
  output_activation: "tanh"
  buffer_capacity: 5000
  batch_size: 64
  gamma: 0.99
  critic_lr: 0.002
  actor_lr: 0.001
  tau: 0.005
  actor:
    layers: [128, 128]
    activations: ['relu', 'relu']
  critic:
    state_out_layers: [16, 32]
    state_out_activations: ["relu", "relu"]
    action_out_layers: [32]
    action_out_activations: ["relu"]
    out_layers: [128, 128]
    out_activations: ["relu", "relu"]
fcmadrl:
  max_episodes: 50000
  max_steps: 25
  num_agents: 2
  dqn_update_target_network: 10
  checkpoint: 50
  logs_dir: "logs/fcmadrl_exp_2"
  save_dir: "save-dir/fcmadrl_exp_2"
  communication:
    message_len: 5
    lower_bound: -5.0
    upper_bound: 5.0